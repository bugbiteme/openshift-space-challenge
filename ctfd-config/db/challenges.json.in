{
  "count": 8,
  "results": [
    {
      "id": 1,
      "name": "The Captain's Log",
      "description": "This ship's computer will keep track of your progress in the Captain's Log.  But first you need to identify yourself to the Log Computer.\r\n\r\n## Objective:\r\nYour current name is `playerX`.   Please change this to your real name and also add your email address.  This will be important to have a chance to win prizes.\r\n\r\n## Specifications:\r\nIn the top right corner, click on \"Settings\"\r\nChange the User Name for your full name:  e.g.  John Smith\r\nChange the Email address:  e.g. jsmith@mycompany.com\r\n\r\nOnce completed, enter \"DONE\" in the flag section and click submit to receive your first point!\r\n",
      "max_attempts": 0,
      "value": 10,
      "category": "Warm Up",
      "type": "standard",
      "state": "visible",
      "requirements": null,
      "connection_info": null,
      "next_id": null
    },
    {
      "id": 2,
      "name": "Unlock the ship",
      "description": "Wait for the game master to provide a KEY to unlock the rest of the island.  \r\nEnter this key in the flag section and click submit.\r\n\r\n",
      "max_attempts": 0,
      "value": 11,
      "category": "Warm Up",
      "type": "standard",
      "state": "visible",
      "requirements": null,
      "connection_info": null,
      "next_id": null
    },
    {
      "id": 3,
      "name": "Engine Trouble",
      "description": "As you explore the station, you come across the main engine room and notice a troubling sight: the ships engine, a late model StarLight XL, is broken beyond repair; a tangle of scorched circuits and shattered components! With no other options, you scour the storage bays and, to your relief, find a brand new QuantumPulse Thruster 3000 waiting to be installed! After some effort, you manage to replace the broken engine with the new one.\r\n\r\n<center><img src=\"files/fb643847e5cdc729d5641f99058fb5e1/manual.jpg\"/></center>\r\n\r\nHowever, a new problem arises. The HAL 8000 AI, which controls the station's systems, has no knowledge of this new QuantumPulse model!  Without understanding how to operate it, HAL 8000 can't start or manage the new engine.\r\n\r\nIn your search for solutions, hidden within the bubble-wrap for the engine, you discover the [QuantumPulse 3000 Owner's Manual](https://gitea-gitea.apps.{{ cluster_url }}/starter/INSTRUCTIONS/raw/branch/master/resources/quantumpulse-3000.md)! This manual is your key to bringing HAL 8000 up to speed, but it needs to be processed into a format the AI can understand. You'll need to implement a Retrieval Augmented Generation (RAG) system to enable HAL 8000 to access and learn from the manual.\r\n\r\n## Objective:\r\nYour first task is to deploy a vector database, ChromaDB, within the OpenShift cluster. This database will store embeddings—numerical representations of text—from the new engine manual. Once ChromaDB is operational, HAL 8000 can query it to retrieve crucial information about the engine's operation.\r\n\r\n## Specification:\r\n\r\nA container image for chromadb can be found in a public container registry at `quay.io/atgreen0/chroma:latest`.\r\n\r\nTry deploying chromadb in your namespace.  Looking at the chroma startup logs, how many components does it start?\r\n\r\n* ocp: https://console-openshift-console.apps.{{ cluster_url }}",
      "max_attempts": 0,
      "value": 50,
      "category": "RAG to the Rescue",
      "type": "standard",
      "state": "visible",
      "requirements": {
        "prerequisites": [
          2
        ]
      },
      "connection_info": null,
      "next_id": null
    },
    {
      "id": 4,
      "name": "Chunk It Up",
      "description": "In order to populate your vector database, you will need to split up the [QuantumPulse 3000's Owner Manual](https://gitea-gitea.apps.{{ cluster_url }}/starter/INSTRUCTIONS/raw/branch/master/resources/quantumpulse-3000.md) into smaller chunks of text before feeding those to an embedding model to generate vectors for the vector database.  But we can take this one step at a time.\r\n\r\n## Objective:\r\nWrite code to read the markdown-formatted Owner's Manual, and split it up into fixed chunk sizes. Count the number of chunks.\r\n\r\n## Specification:\r\nEach chunk size should contain eight paragraphs of text.  More specifically, for the purposes of this challenge, any fragment of text separated by a blank line is a paragraph, even if it is only one line long (eg. a section header).  The final chunk may be less than eight paragraphs.  For now, we don't need to save the chunks anywhere -- just count them.\r\n\r\nHow many eight-paragraph chunks exist in the [QuantumPulse 3000's Owner Manual](https://gitea-gitea.apps.{{ cluster_url }}/starter/INSTRUCTIONS/raw/branch/master/resources/quantumpulse-3000.md)?\r\n\r\n* gitea: https://gitea-gitea.apps.{{ cluster_url }}\r\n* ocp: https://console-openshift-console.apps.{{ cluster_url }}\r\n* manual: https://gitea-gitea.apps.{{ cluster_url }}/starter/INSTRUCTIONS/raw/branch/master/resources/quantumpulse-3000.md\r\n",
      "max_attempts": 0,
      "value": 50,
      "category": "RAG to the Rescue",
      "type": "standard",
      "state": "visible",
      "requirements": {
        "prerequisites": [
          2,
          3
        ]
      },
      "connection_info": null,
      "next_id": null
    },
    {
      "id": 5,
      "name": "Embedding",
      "description": "An embedding model is an AI model specifically trained to generate long lists of numbers (vectors) representing the semantic meaning of a chunk of text.  You can read more about embedding models here: https://ollama.com/blog/embedding-models\r\n\r\nYou'll need an embedding model to populate your vector database with the text you will chunk out from the [QuantumPulse 3000's Owner Manual](https://gitea-gitea.apps.{{ cluster_url }}/starter/INSTRUCTIONS/raw/branch/master/resources/quantumpulse-3000.md). Fortunately, Space Command provided an emedding model (`nomic-embed-text`) that you should be able to deploy on the ship's OpenShift cluster.\r\n\r\n# Objective:\r\nDeploy and test an embedding model on OpenShift.\r\n\r\n# Specifications:\r\nThere's an embedding model available for deployment at `quay.io/atgreen0/ollama-embedding:latest`.  Deploy this container image in your namespace.  To ensure that it is working, let's generate our first vector.   In the model's pod terminal run this:\r\n```\r\ncurl http://localhost:8080/api/embeddings -d '{\r\n  \"model\": \"nomic-embed-text\",\r\n  \"prompt\": \"The speed of light in a vacuum is approximately 299,792,458 m/s.\"\r\n}'\r\n```\r\nThe model should have responded with a JSON object containing a vector of numbers.  What is the very last number in the vector?\r\n\r\n* gitea: https://gitea-gitea.apps.{{ cluster_url }}\r\n* ocp: https://console-openshift-console.apps.{{ cluster_url }}\r\n",
      "max_attempts": 0,
      "value": 50,
      "category": "RAG to the Rescue",
      "type": "standard",
      "state": "visible",
      "requirements": {
        "prerequisites": [
          2,
          3,
          4
        ]
      },
      "connection_info": null,
      "next_id": null
    },
    {
      "id": 6,
      "name": "API service down",
      "description": "\r\nYour ship computer API service is down.\r\n\r\n## Objective:\r\nRestart your computer API service in OpenShift.  This will allow you to communicate with the ship using code in future challenges.  \r\n\r\n\r\n## Specification:\r\n\r\nA container image for the api service can be found in a public container registry at \r\n`quay.io/mberube/api_service:latest`\r\n\r\nIn your project (nameplace) playerX, run this image as a container pod and make sure to add a route to be able to reach this service.   This can easily be done in Add=>Container image.\r\n\r\nFinally, to retrieve the oxygen level on the ship, hit the following api endpoint with your browser:  /api/v1/oxygen\r\n\r\nConfirm the oxygen level as your flag for this challenge to receive your points.\r\n\r\n* ocp: https://console-openshift-console.apps.{{ cluster_url }}\r\n\r\n",
      "max_attempts": 0,
      "value": 10,
      "category": "Warm Up",
      "type": "standard",
      "state": "visible",
      "requirements": null,
      "connection_info": null,
      "next_id": null
    },
    {
      "id": 7,
      "name": "Temperature control",
      "description": "## Objective:\r\nLet's validate that the ambient temperature on the ship is ok.\r\n\r\n\r\n## Specification:\r\n\r\nUse the ship computer api service again to retrieve the temperature on the ship for all the rooms.    You should already have the api service running from the warm up phase,  just reach the temperature api endpoint to retrieve this information:   /api/v1/temperature\r\n\r\nLet's calculate the average temperature on the ship and return that value as the flag to get your points.\r\n\r\n* ocp: https://console-openshift-console.apps.cluster-rttcz.rttcz.sandbox1949.opentlc.com\r\n",
      "max_attempts": 0,
      "value": 20,
      "category": "Basic controls",
      "type": "standard",
      "state": "visible",
      "requirements": null,
      "connection_info": null,
      "next_id": null
    },
    {
      "id": 8,
      "name": "Speed control",
      "description": "## Objective:\r\nAs we are approaching planet Nerdoria's orbit, we realize that we might not be arrive on time.   Punctuality is very important for Nerdorians, we must arrive exactly at 7pm Nerdoria Standard Time.    Adjust your ship speed to make sure we arrive exactly on-time.\r\n\r\n\r\n## Specification:\r\n\r\nUse the ship api service again to look at our front camera and detect the exact distance between our ship and this planet.   You can access this front camera at:  /api/v1/camera1\r\n\r\nThen, adjust the speed of our ship in km/s to arrive exactly at 7:00pm NST.     The current time on Nedoria is 1:16pm.\r\nThis can be done by doing an HTTP POST to the speed control api:  /api/v1/speed\r\n\r\nOur reputation is in your hands.    \r\n\r\nIf the speed is adjust correct, the API server will give you the right flag.     If the speed is incorrect, you might get a wrong flag.\r\n\r\n* ocp: https://console-openshift-console.apps.cluster-rttcz.rttcz.sandbox1949.opentlc.com\r\n",
      "max_attempts": 0,
      "value": 25,
      "category": "Basic controls",
      "type": "standard",
      "state": "visible",
      "requirements": null,
      "connection_info": null,
      "next_id": null
    }
  ],
  "meta": {}
}
