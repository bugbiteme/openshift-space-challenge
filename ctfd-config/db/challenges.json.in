{
  "count": 11,
  "results": [
    {
      "id": 1,
      "name": "The Captain's Log",
      "description": "This ship's computer will keep track of your progress in the Captain's Log.  But first you need to identify yourself to the Log Computer.\r\n\r\n### Objective:\r\nYour current name is `playerX`.   Please change this to your real name and also add your email address.  This will be important to have a chance to win prizes.\r\n\r\n### Specifications:\r\nIn the top right corner, click on \"Settings\"\r\nChange the User Name for your full name:  e.g.  John Smith\r\nChange the Email address:  e.g. jsmith@mycompany.com\r\n\r\nOnce completed, enter \"DONE\" in the flag section and click submit to receive your first point!\r\n",
      "max_attempts": 0,
      "value": 10,
      "category": "Warm Up",
      "type": "standard",
      "state": "visible",
      "requirements": null,
      "connection_info": null,
      "next_id": null
    },
    {
      "id": 2,
      "name": "Unlock the ship",
      "description": "Wait for the game master to provide a KEY to unlock the rest of the island.  \r\nEnter this key in the flag section and click submit.\r\n\r\n",
      "max_attempts": 0,
      "value": 11,
      "category": "Warm Up",
      "type": "standard",
      "state": "visible",
      "requirements": null,
      "connection_info": null,
      "next_id": null
    },
    {
      "id": 3,
      "name": "Engine Trouble",
      "description": "As you explore the station, you come across the main engine room and notice a troubling sight: the ships engine, a late model StarLight XL, is broken beyond repair; a tangle of scorched circuits and shattered components! With no other options, you scour the storage bays and, to your relief, find a brand new QuantumPulse Thruster 3000 waiting to be installed! After some effort, you manage to replace the broken engine with the new one.\r\n\r\n<center><img src=\"files/fb643847e5cdc729d5641f99058fb5e1/manual.jpg\"/></center>\r\n\r\nHowever, a new problem arises. The HAL 8000 AI, which controls the station's systems, has no knowledge of this new QuantumPulse model!  Without understanding how to operate it, HAL 8000 can't start or manage the new engine.\r\n\r\nIn your search for solutions, hidden within the bubble-wrap for the engine, you discover the [QuantumPulse 3000 Owner's Manual](https://gitea-gitea.apps.{{ cluster_url }}/starter/INSTRUCTIONS/raw/branch/master/resources/quantumpulse-3000.md)! This manual is your key to bringing HAL 8000 up to speed, but it needs to be processed into a format the AI can understand. You'll need to implement a Retrieval Augmented Generation (RAG) system to enable HAL 8000 to access and learn from the manual.\r\n\r\n### Objective:\r\nYour first task is to deploy a vector database, ChromaDB, within the OpenShift cluster. This database will store embeddings—numerical representations of text—from the new engine manual. Once ChromaDB is operational, HAL 8000 can query it to retrieve crucial information about the engine's operation.\r\n\r\n### Specification:\r\n\r\nA container image for chromadb can be found in a public container registry at `quay.io/atgreen0/chroma:latest`.\r\n\r\nTry deploying chromadb in your namespace.  Looking at the chroma startup logs, how many components does it start?\r\n\r\n* ocp: https://console-openshift-console.apps.{{ cluster_url }}",
      "max_attempts": 0,
      "value": 50,
      "category": "RAG to the Rescue",
      "type": "standard",
      "state": "visible",
      "requirements": {
        "prerequisites": [
          2
        ]
      },
      "connection_info": null,
      "next_id": null
    },
    {
      "id": 5,
      "name": "Chunk It Up",
      "description": "In order to populate your vector database, you will need to split up the [QuantumPulse 3000's Owner Manual](https://gitea-gitea.apps.{{ cluster_url }}/starter/INSTRUCTIONS/raw/branch/master/resources/quantumpulse-3000.md) into smaller chunks of text before feeding those to an embedding model to generate vectors for the vector database.  But we can take this one step at a time.\r\n\r\n### Objective:\r\nWrite code to read the markdown-formatted Owner's Manual, and split it up into fixed chunk sizes. Count the number of chunks.\r\n\r\n### Specification:\r\nEach chunk size should contain eight paragraphs of text.  More specifically, for the purposes of this challenge, any fragment of text separated by a blank line is a paragraph, even if it is only one line long (eg. a section header).  The final chunk may be less than eight paragraphs.  For now, we don't need to save the chunks anywhere -- just count them.\r\n\r\nHow many eight-paragraph chunks exist in the [QuantumPulse 3000's Owner Manual](https://gitea-gitea.apps.{{ cluster_url }}/starter/INSTRUCTIONS/raw/branch/master/resources/quantumpulse-3000.md)?\r\n\r\n* gitea: https://gitea-gitea.apps.{{ cluster_url }}\r\n* ocp: https://console-openshift-console.apps.{{ cluster_url }}\r\n* manual: https://gitea-gitea.apps.{{ cluster_url }}/starter/INSTRUCTIONS/raw/branch/master/resources/quantumpulse-3000.md\r\n",
      "max_attempts": 0,
      "value": 50,
      "category": "RAG to the Rescue",
      "type": "standard",
      "state": "visible",
      "requirements": {
        "prerequisites": [
          2,
          3,
          4
        ]
      },
      "connection_info": null,
      "next_id": null
    },
    {
      "id": 4,
      "name": "Embedding",
      "description": "An embedding model is an AI model specifically trained to generate long lists of numbers (vectors) representing the semantic meaning of a chunk of text.  You can read more about embedding models here: https://ollama.com/blog/embedding-models\r\n\r\nYou'll need an embedding model to populate your vector database with the text you will chunk out from the [QuantumPulse 3000's Owner Manual](https://gitea-gitea.apps.{{ cluster_url }}/starter/INSTRUCTIONS/raw/branch/master/resources/quantumpulse-3000.md). Fortunately, Space Command provided an emedding model (`nomic-embed-text`) that you should be able to deploy on the ship's OpenShift cluster.\r\n\r\n## Objective:\r\nDeploy and test an embedding model on OpenShift.\r\n\r\n## Specifications:\r\nThere's an embedding model available for deployment at `quay.io/atgreen0/ollama-embedding:latest`.  Deploy this container image in your namespace.  To ensure that it is working, let's generate our first vector.   In the model's pod terminal run this:\r\n```\r\ncurl http://localhost:8080/api/embeddings -d '{\r\n  \"model\": \"nomic-embed-text\",\r\n  \"prompt\": \"The speed of light in a vacuum is approximately 299,792,458 m/s.\"\r\n}'\r\n```\r\nThe model should have responded with a JSON object containing a vector of numbers.  What is the very last number in the vector?\r\n\r\n* gitea: https://gitea-gitea.apps.{{ cluster_url }}\r\n* ocp: https://console-openshift-console.apps.{{ cluster_url }}\r\n",
      "max_attempts": 0,
      "value": 50,
      "category": "RAG to the Rescue",
      "type": "standard",
      "state": "visible",
      "requirements": {
        "prerequisites": [
          2,
          3
        ]
      },
      "connection_info": null,
      "next_id": null
    },
    {
      "id": 6,
      "name": "API service down",
      "description": "\r\nYour ship computer API service is down.\r\n\r\n### Objective:\r\nRestart your computer API service in OpenShift.  This will allow you to communicate with the ship using code in future challenges.  \r\n\r\n\r\n### Specification:\r\n\r\nA container image for the api service can be found in a public container registry at \r\n`quay.io/atgreen0/ship_api:latest`\r\n\r\nIn your project (nameplace) playerX, run this image as a container pod and make sure to add a route to be able to reach this service.   This can easily be done in Add=>Container image.\r\n\r\nFinally, to retrieve the oxygen level on the ship, hit the following api endpoint with your browser:  /api/v1/oxygen\r\n\r\nConfirm the oxygen level as your flag for this challenge to receive your points.\r\n\r\n* ocp: https://console-openshift-console.apps.{{ cluster_url }}\r\n\r\n",
      "max_attempts": 0,
      "value": 10,
      "category": "Warm Up",
      "type": "standard",
      "state": "visible",
      "requirements": null,
      "connection_info": null,
      "next_id": null
    },
    {
      "id": 7,
      "name": "Temperature control",
      "description": "### Objective:\r\nLet's validate that the ambient temperature on the ship is ok.\r\n\r\n\r\n### Specification:\r\n\r\nUse the ship computer api service again to retrieve the temperature on the ship for all the rooms.    You should already have the api service running from the warm up phase,  just reach the temperature api endpoint to retrieve this information:   /api/v1/temperature\r\n\r\nLet's calculate the average temperature on the ship and return that value as the flag to get your points.\r\n\r\n* ocp: https://console-openshift-console.apps.{{ cluster_url }}\r\n",
      "max_attempts": 0,
      "value": 20,
      "category": "Basic controls",
      "type": "standard",
      "state": "visible",
      "requirements": {
        "prerequisites": [
          2
        ]
      },
      "connection_info": null,
      "next_id": null
    },
    {
      "id": 8,
      "name": "Speed control",
      "description": "### Objective:\r\nAs we are approaching planet Nerdoria's orbit, we realize that we might not be arrive on time.   Punctuality is very important for Nerdorians, we must arrive exactly at 7pm Nerdoria Standard Time.    Adjust your ship speed to make sure we arrive exactly on-time.\r\n\r\n\r\n### Specification:\r\n\r\nUse the ship api service again to look at our front camera and detect the exact distance between our ship and this planet.   You can access this front camera at:  /api/v1/camera1\r\n\r\nThen, adjust the speed of our ship in km/s to arrive exactly at 7:00pm NST.     The current time on Nedoria is 1:16pm.\r\nThis can be done by doing an HTTP POST to the speed control api:  /api/v1/speed\r\n\r\nOur reputation is in your hands.    \r\n\r\nIf the speed is adjust correct, the API server will give you the right flag.     If the speed is incorrect, you might get a wrong flag.\r\n\r\n* ocp: https://console-openshift-console.apps.{{ cluster_url }}\r\n",
      "max_attempts": 0,
      "value": 25,
      "category": "Basic controls",
      "type": "standard",
      "state": "visible",
      "requirements": {
        "prerequisites": [
          2
        ]
      },
      "connection_info": null,
      "next_id": null
    },
    {
      "id": 9,
      "name": "RAG Service",
      "description": "Now that we have a working embedding model and Vector DB, it's time to build the service the ship's AI will call to ask about the [QuantumPulse 3000's Owner Manual](https://gitea-gitea.apps.{{ cluster_url }}/starter/INSTRUCTIONS/raw/branch/master/resources/quantumpulse-3000.md).\r\n## Objective:\r\nImplement a service on the ship's OpenShift cluster that will accept posts from the ship's AI, and find relevant text from the vector DB.  To solve this, you will need to write a service that will:\r\n- populate the vectordb with the chunked text you have already created.\r\n- respond to https posts from the ship's AI to find the closest matching text from the DB.\r\n\r\nTo retrieve the flag, tell the API server to test your implementation by hitting the `/api/v1/test-rag` endpoint.\r\n\r\n## Specifications:\r\n**Endpoint:** POST /\r\n\r\n**Input:** Plain text body describing what the AI wants to learn about.\r\n\r\n**Response:** JSON output from the vector database.\r\n\r\nThe **starter** user on gitea contains sample starter repos showing how to interact with the vector DB\r\n\r\n* ocp: https://console-openshift-console.apps.{{ cluster_url }}\r\n* node RAG starter: https://gitea-gitea.apps.{{ cluster_url }}/starter/node-rag-starter\r\n",
      "max_attempts": 0,
      "value": 50,
      "category": "RAG to the Rescue",
      "type": "standard",
      "state": "visible",
      "requirements": {
        "prerequisites": [
          2,
          3,
          4,
          5
        ]
      },
      "connection_info": null,
      "next_id": null
    },
    {
      "id": 10,
      "name": "Turtle Count",
      "description": "As you delve deeper into the mysteries of the space station, your exploration brings you to an unexpected discovery. In a remote section of the station, you find a communication relay buzzing with faint activity. The source of the signal is puzzling—a race of space-faring turtles known as the Chelonids, who communicate through intricate patterns and symbols. These beings, renowned for their wisdom and ancient knowledge, are trying to send you a message, but their communication method is unlike anything you've seen before.\r\n\r\nTheir message is being sent in fragments that must be assembled together in order to be interpreted correctly.  However, damage to the turtlecomms input array buffer has the messages arriving out of order. The good news is that the Chelonids are sending the same series of message fragments over and over again in a repeating loop, so if you wait long enough you are sure to capture them all.\r\n\r\n### Objective\r\n\r\nYour first objective is to create a service that can receive the turtle instruction messages and sort them into the right order. Your flag is the total number of steps in the message sequence.\r\n\r\n### Specification\r\n\r\nImplement an http service that listens for incoming JSON POST messages containing turtle instructions.  The service should be called `turtlecomms` and the endpoint is `\\instruction`.  JSON messages will be posted to `turtlecomms` via http on port 8080.  The ship is routing incoming messages through your `ship-api` service, so there is no need to provide an external route to this service.\r\n\r\nEach message will contain a sequence number (`seq`) and an instruction (`instruction`).  The instructions are arriving out of order, but once they are sorted they start at 1 and each instruction step goes up by 1.  The sequence of instructions ends with an empty `instruction` (\"\") and is not included the in total count of sequence steps.\r\n\r\nYour first flag is simply the number of steps in the message sequence.\r\n\r\n* ocp: https://console-openshift-console.apps.{{ cluster_url }}\r\n* gitea: https://gitea-gitea.apps.{{ cluster_url }}\r\n",
      "max_attempts": 0,
      "value": 50,
      "category": "Space Turtles",
      "type": "standard",
      "state": "visible",
      "requirements": {
        "prerequisites": [
            2,
            6
        ]
      }
    },
    {
      "id": 11,
      "name": "Turtle Draw",
      "description": "Now that you've received all of the instruction steps, it's time to decode the message (your flag).\r\n\r\nUpon careful examination, you realize that the instruction steps are reminiscent of the old \"turtle graphics\" used in computer programming. These instructions direct a virtual pen to move and draw patterns, revealing hidden messages when interpreted correctly.\r\n\r\n### Objective\r\n\r\nYour objective is to move a virtual pen-wielding turtle through a two-dimensional grid in order to render an image that will reveal their message (your flag).\r\n\r\n### Specification\r\n\r\nTurtle graphics are written on a two-dimensional grid.  Each cell in the grid starts off empty.  A cell is marked with `#` whenever the pen is placed down in a cell, or the turtle travels through a cell while the pen is down.  The turtle can only travel forward, turn left 90 degrees, and turn right 90 degrees.\r\n\r\nInstructions include the following commands:\r\n- `PU`: lift the pen up\r\n- `PD`: place the pen down\r\n- `F[number]`: move forward `[number]` grid cells\r\n- `R`: turn right 90 degrees\r\n- `L`: turn left 90 degrees\r\n\r\nFollow the Chelonids' instructions in order, starting with instruction 1.  Display the final grid in your console logs or on a web page in order to retrieve the flag for this challenge.\r\n\r\n* ocp: https://console-openshift-console.apps.{{ cluster_url }}\r\n* gitea: https://gitea-gitea.apps.{{ cluster_url }}\r\n",
      "max_attempts": 0,
      "value": 50,
      "category": "Space Turtles",
      "type": "standard",
      "state": "visible",
      "requirements": {
        "prerequisites": [
            2,
            6,
            10
        ]
      },
      "connection_info": null,
      "next_id": null
    },
    {
      "id": 13,
      "name": "Planet database",
        "description": "### Objective:\r\n🚨 Alert! 🚨 We've got smoke billowing out of the mechanical room!\r\n\r\nThe good news? Our top-notch robot mechanic, R2FixU, has already pinpointed the issue. The bad news? Fixing it in the cold, unforgiving void of space is a no-go. We need to land, and we need to land fast—before things get as messy as a Wookiee’s hairball.\r\n\r\nFirst things first, let's fire up the ol' planet database and find the nearest rock we can safely park this hunk of metal on. \r\n\r\n\r\n### Specification:\r\n\r\nA container image with the database can be found in a public container registry at \r\n`quay.io/mberube/planetdb:latest`\r\n\r\nLaunch this image on OpenShift and make sure to use the following environment variables to configure your database properly:\r\n\r\n* MYSQL_ROOT_PASSWORD\r\n* MYSQL_DATABASE\r\n* MYSQL_USER\r\n* MYSQL_PASSWORD\r\n\r\nFeel free to set those variables to any value you want.  just make sure that you will remember those values as you will need to connect to this database.\r\n\r\nIn this database, you will find a \"planets\" table.   Find a way to count the number of planets listed in this table.    Type the number of planet as your flag.\r\n\r\n* ocp: https://console-openshift-console.apps.{{ cluster_url }}",
      "max_attempts": 0,
      "value": 30,
      "category": "Emergency landing",
      "type": "standard",
      "state": "visible",
      "requirements": {
        "prerequisites": [
          2
        ]
      },
      "connection_info": null,
      "next_id": null
    },
    {
      "id": 14,
      "name": "Closest planet",
        "description": "### Objective:\r\nNow that our database is running, let's find the cloest planet.   Our current ship coordinates are:  \r\n\r\ngalactic_latitude = 15.23\r\ngalactic_longitude = 95.3\r\n\r\n\r\n### Specification:\r\n\r\nLook into your gitea repository, you should find some code helping you get started and connect to a mysql database.     Modify this code to find the closest planet to our current location.\r\n\r\nType the name of this planet as the flag below to get your points.\r\n\r\n\r\n* ocp: https://console-openshift-console.apps.{{ cluster_url }}",
      "max_attempts": 0,
      "value": 100,
      "category": "Emergency landing",
      "type": "standard",
      "state": "visible",
      "requirements": {
      "prerequisites": [
          2,
          13
        ]
      },
      "connection_info": null,
      "next_id": null
    }
  ],
  "meta": {}
}
