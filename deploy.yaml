---
- name: Deploy CTFd
  hosts: localhost
  gather_facts: false
  connection: local
  vars:
    project_name: "ctfd"
    player_count: 100
  tasks:

  tasks:
    - name: create {{ project_name }} namespace
      kubernetes.core.k8s:
        api_version: v1
        kind: Namespace
        name: "{{ project_name }}"
        state: present
        wait: yes
      retries: 20
      delay: 15

    - name: create imagestream
      kubernetes.core.k8s:
        api_version: image.openshift.io/v1
        namespace: "{{ project_name }}"
        kind: ImageStream
        name: "ctfd"
        state: present
        wait: yes
      retries: 20
      delay: 15

    - name: create buildconfig for CTFd
      kubernetes.core.k8s:
        namespace: "{{ project_name }}"
        definition:
          apiVersion: build.openshift.io/v1
          kind: BuildConfig
          metadata:
            annotations:
            labels:
              app: ctfd
            name: ctfd
          spec:
            output:
              to:
                kind: ImageStreamTag
                name: ctfd:latest
            triggers:
              - type: "ConfigChange"
            source:
              git:
                ref: master
                uri: https://github.com/catalyst-ctfd/CTFd
              contextDir:
              type: Git
            strategy:
              dockerStrategy:
                from:
                  kind: DockerImage
                  name: python:3.9-slim-buster
                forcePull: true
                noCache: true
              type: Docker
        wait: yes
      retries: 20
      delay: 15

    - name: create mysql pvc
      kubernetes.core.k8s:
        namespace: "{{ project_name }}"
        definition:
          apiVersion: v1
          kind: PersistentVolumeClaim
          metadata:
            namespace: "{{ project_name }}"
            creationTimestamp: null
            labels:
              ctfd: mysql-pv
              app: ctfd-mysql-db-pv
            name: ctfd-mysql-db-pv
          spec:
            accessModes:
            - ReadWriteOnce
            resources:
              requests:
                storage: 1Gi
      retries: 20
      delay: 15

    - name: create mysql deployment
      kubernetes.core.k8s:
        namespace: "{{ project_name }}"
        definition:
          apiVersion: apps/v1
          kind: Deployment
          metadata:
            namespace: "{{ project_name }}"
            creationTimestamp: null
            labels:
              ctfd: mysql
              app: ctfd-mysql-db
            name: ctfd-mysql-db
          spec:
            replicas: 1
            selector:
              matchLabels:
                app: ctfd-mysql-db
            strategy:
              type: Recreate
            template:
              metadata:
                creationTimestamp: null
                labels:
                  ctfd: mysql
                  app: ctfd-mysql-db
              spec:
                containers:
                - args:
                  - mysqld
                  - --character-set-server=utf8mb4
                  - --collation-server=utf8mb4_unicode_ci
                  - --wait_timeout=28800
                  - --log-warnings=0
                  env:
                  - name: MYSQL_DATABASE
                    value: ctfd
                  - name: MYSQL_PASSWORD
                    value: ctfd
                  - name: MYSQL_ROOT_PASSWORD
                    value: ctfd
                  - name: MYSQL_USER
                    value: ctfd
                  image: mariadb:10.4.12
                  imagePullPolicy: ""
                  name: ctfd-mysql-db
                  resources: {}
                  volumeMounts:
                  - mountPath: /var/lib/mysql
                    name: ctfd-mysql-db-pv
                restartPolicy: Always
                serviceAccountName: ""
                automountServiceAccountToken: false
                volumes:
                - name: ctfd-mysql-db-pv
                  persistentVolumeClaim:
                    claimName: ctfd-mysql-db-pv
      retries: 20
      delay: 15

    - name: create mysql service
      kubernetes.core.k8s:
        namespace: "{{ project_name }}"
        definition:
          apiVersion: v1
          kind: Service
          metadata:
            namespace: "{{ project_name }}"
            creationTimestamp: null
            labels:
              app: ctfd-mysql-db
            name: ctfd-mysql-db
          spec:
            ports:
            - name: mysql
              port: 3306
              protocol: TCP
              targetPort: 3306
            selector:
              app: ctfd-mysql-db
            type: ClusterIP
      retries: 20
      delay: 15

    - name: create redis pvc
      kubernetes.core.k8s:
        namespace: "{{ project_name }}"
        definition:
          apiVersion: v1
          kind: PersistentVolumeClaim
          metadata:
            namespace: "{{ project_name }}"
            creationTimestamp: null
            name: ctfd-redis-cache-pv
            labels:
              ctfd: redis-pv
              app: ctfd-redis-cache-pv
          spec:
            accessModes:
            - ReadWriteOnce
            resources:
              requests:
                storage: 200Mi
      retries: 20
      delay: 15

    - name: create redis deployment
      kubernetes.core.k8s:
        namespace: "{{ project_name }}"
        definition:
          apiVersion: apps/v1
          kind: Deployment
          metadata:
            namespace: "{{ project_name }}"
            creationTimestamp: null
            name: ctfd-redis-cache
            labels:
              ctfd: redis
              app: ctfd-redis-cache
          spec:
            replicas: 1
            selector:
              matchLabels:
                app: ctfd-redis-cache
            strategy:
              type: Recreate
            template:
              metadata:
                creationTimestamp: null
                labels:
                  ctfd: redis
                  app: ctfd-redis-cache
              spec:
                containers:
                - image: redis:4
                  imagePullPolicy: ""
                  name: ctfd-redis-cache
                  resources: {}
                  volumeMounts:
                  - mountPath: /data
                    name: ctfd-redis-cache-pv
                restartPolicy: Always
                serviceAccountName: ""
                automountServiceAccountToken: false
                volumes:
                - name: ctfd-redis-cache-pv
                  persistentVolumeClaim:
                    claimName: ctfd-redis-cache-pv
      retries: 20
      delay: 15

    - name: create redis service
      kubernetes.core.k8s:
        namespace: "{{ project_name }}"
        definition:
          apiVersion: v1
          kind: Service
          metadata:
            namespace: "{{ project_name }}"
            creationTimestamp: null
            labels:
              app: ctfd-redis-cache
            name: ctfd-redis-cache
          spec:
            ports:
            - name: redis
              port: 6379
              protocol: TCP
              targetPort: 6379
            selector:
              app: ctfd-redis-cache
            type: ClusterIP
      retries: 20
      delay: 15

    - name: create ctfd logs pvc
      kubernetes.core.k8s:
        namespace: "{{ project_name }}"
        definition:
          apiVersion: v1
          kind: PersistentVolumeClaim
          metadata:
            creationTimestamp: null
            labels:
              ctfd: ctf-pv
              app: ctf-pv-logs
            name: ctf-pv-logs
          spec:
            accessModes:
            - ReadWriteOnce
            resources:
              requests:
                storage: 200Mi
      retries: 20
      delay: 15

    - name: create ctfd uploads pvc
      kubernetes.core.k8s:
        namespace: "{{ project_name }}"
        definition:
          apiVersion: v1
          kind: PersistentVolumeClaim
          metadata:
            creationTimestamp: null
            labels:
              ctfd: ctf-pv
              app: ctfd-pv-uploads
            name: ctfd-pv-uploads
          spec:
            accessModes:
            - ReadWriteOnce
            resources:
              requests:
                storage: 500Mi
      retries: 20
      delay: 15

    - name: create ctfd deployment
      kubernetes.core.k8s:
        namespace: "{{ project_name }}"
        definition:
          apiVersion: apps/v1
          kind: Deployment
          metadata:
            name: ctfd
            labels:
              ctfd: ctfd
              app: ctfd
          spec:
            replicas: 1
            selector:
              matchLabels:
                app: ctfd
            template:
              metadata:
                labels:
                  ctfd: ctfd
                  app: ctfd
              spec:
                containers:
                - env:
                  - name: ACCESS_LOG
                    value: '-'
                  - name: DATABASE_URL
                    value: mysql+pymysql://ctfd:ctfd@ctfd-mysql-db/ctfd
                  - name: ERROR_LOG
                    value: '-'
                  - name: LOG_FOLDER
                    value: /var/log/CTFd
                  - name: REDIS_URL
                    value: redis://ctfd-redis-cache:6379
                  - name: REVERSE_PROXY
                    value: "true"
                  - name: UPLOAD_FOLDER
                    value: /var/uploads
                  - name: WORKERS
                    value: "1"
                  image: "image-registry.openshift-image-registry.svc:5000/{{ project_name }}/ctfd:latest"
                  imagePullPolicy: ""
                  name: ctfd
                  resources: {}
                  volumeMounts:
                  - mountPath: /var/log/CTFd
                    name: ctf-pv-logs
                  - mountPath: /var/uploads
                    name: ctfd-pv-uploads
                restartPolicy: Always
                serviceAccountName: ""
                automountServiceAccountToken: false
                volumes:
                - name: ctf-pv-logs
                  persistentVolumeClaim:
                    claimName: ctf-pv-logs
                - name: ctfd-pv-uploads
                  persistentVolumeClaim:
                    claimName: ctfd-pv-uploads
      retries: 20
      delay: 15

    - name: create ctfd service
      kubernetes.core.k8s:
        namespace: "{{ project_name }}"
        definition:
          apiVersion: v1
          kind: Service
          metadata:
            labels:
              app: ctfd
            name: ctfd
          spec:
            ports:
            - name: ui
              port: 8000
              protocol: TCP
              targetPort: 8000
            selector:
              app: ctfd
            type: ClusterIP
      retries: 20
      delay: 15

    - name: create island route
      kubernetes.core.k8s:
        namespace: "{{ project_name }}"
        definition:
          kind: Route
          apiVersion: route.openshift.io/v1
          metadata:
            name: island
            labels:
              app: ctfd
          spec:
            to:
              kind: Service
              name: ctfd
              weight: 100
            port:
              targetPort: ui
            tls:
              termination: edge
            wildcardPolicy: None
      retries: 20
      delay: 15

    - name: create gitea operator
      shell: oc apply -k https://github.com/rhpds/gitea-operator/OLMDeploy

    - name: create gitea namespace
      kubernetes.core.k8s:
        api_version: v1
        kind: Namespace
        name: gitea
        state: present
        wait: yes
      retries: 20
      delay: 15

    - name: create player accounts
      shell: |
        if [ "$(uname)" = "Darwin" ]; then oc get secret htpasswd -o json -n openshift-config | jq -r '.data.htpasswd' | tr -d ' ' | base64 -D; else oc get secret htpasswd -o json -n openshift-config | jq -r '.data.htpasswd' | tr -d ' ' | base64 -d; fi | grep "admin" > .players.htpasswd
        cat players.htpasswd >> .players.htpasswd
        oc create secret generic htpasswd --from-file=htpasswd=.players.htpasswd -n openshift-config --dry-run=client -o yaml | oc replace -f -

    - name: create player namespaces
      kubernetes.core.k8s:
        api_version: v1
        kind: Namespace
        name: "player{{ item }}"
        state: present
        wait: yes
      with_sequence: start=1 end={{ player_count }}
      retries: 20
      delay: 15

    - name: Assigning players to namespaces
      shell: |
        oc adm policy add-role-to-user edit "player{{ item }}" -n "player{{ item }}"
      with_sequence: start=1 end={{ player_count }}

    - name: Get the cluster console URL
      shell: oc get routes --all-namespaces | grep console-openshift | awk '{ print $3 }'
      register: oc_output

    - name: Extract the cluster domain
      set_fact:
        extracted_domain: "{{ oc_output.stdout.split('apps.')[1] }}"

    - name: Generate gitea custom configmap from template
      template:
        src: gitea_configmap.j2
        dest: /tmp/gitea_configmap.yaml
      vars:
        cluster_domain: "{{ extracted_domain }}"

    - name: Create custom configmap for gitea
      shell: |
        oc apply -f /tmp/gitea_configmap.yaml -n gitea

    - name: create gitea CRD
      kubernetes.core.k8s:
        namespace: gitea
        definition:
          apiVersion: pfe.rhpds.com/v1
          kind: Gitea
          metadata:
            name: gitea
          spec:
            giteaUserNumber: 100
            giteaAdminPasswordLength: 32
            giteaGenerateUserFormat: player%d
            giteaVolumeSize: 4Gi
            giteaAdminUser: gitadmin
            giteaImageTag: 1.20.1
            postgresqlVolumeSize: 4Gi
            giteaDisableRegistration: true
            giteaUserPassword: openshift
            giteaAdminEmail: green@redhat.com
            giteaAdminPassword: redhat123
            giteaCreateUsers: true
            giteaSsl: true
            giteaConfigMapName: custom-gitea-config
            giteaHostname: "gitea-gitea.apps.{{ extracted_domain }}"
            postgresqlSetup: true
            giteaPostgresqlServiceName: postgresql-gitea
            giteaPostgresqlDatabaseName: giteadb
            giteaPostgresqlUser: giteauser
            giteaPostgresqlPassword: giteapassword
      retries: 20
      delay: 15

    - name: Wait for gitea pod to be created
      shell: "oc get pod --namespace=gitea --selector app=gitea --output=jsonpath='{.items[*].metadata.name}'"
      register: gitea_pod_created
      until: item in gitea_pod_created.stdout
      retries: 10
      delay: 30
      with_items:
        - gitea

    - name: Wait for gitea to become ready
      shell: "oc wait --namespace=gitea --for=condition=Ready pods --selector app=gitea --timeout=600s"
      register: gitea_pod_created

    - name: Create ctfd users
      shell: "python3 {{ playbook_dir }}/make-ctfd-users.py > {{ playbook_dir }}/ctfd-config/db/users.json"

    - name: Patch challenges.json file
      template:
        src: "{{ playbook_dir }}/ctfd-config/db/challenges.json.in"
        dest: "{{ playbook_dir }}/ctfd-config/db/challenges.json"
      vars:
        cluster_url: "{{ extracted_domain }}"

    - name: Patch config.json file
      template:
        src: "{{ playbook_dir }}/ctfd-config/db/config.json.in"
        dest: "{{ playbook_dir }}/ctfd-config/db/config.json"
      vars:
        cluster_url: "{{ extracted_domain }}"

    - name: Patch judge config/settings.ini
      template:
        src: "{{ playbook_dir }}/judge/settings.ini.in"
        dest: "{{ playbook_dir }}/judge/settings.ini"
      vars:
        cluster_url: "{{ extracted_domain }}"

    - name: create ctfd archive for uploading
      community.general.archive:
        path:
        - "{{ playbook_dir }}/ctfd-config/"
        exclusion_patterns:
        - "*.in"
        dest: "{{ playbook_dir }}/ctfd-upload-me.zip"
        format: zip

    - name: set gitea passwords
      shell: |
        PODNAME=$(oc get pods -n gitea --selector app=gitea -o custom-columns=POD:.metadata.name --no-headers)
        oc cp gitea-set-passwords.sh $PODNAME:gitea-set-passwords.sh -n gitea
        oc exec $PODNAME -n gitea -- chmod +x ./gitea-set-passwords.sh
        oc exec $PODNAME -n gitea -- sh -c "./gitea-set-passwords.sh > gitea-set-passwords.log 2>&1"
      retries: 20
      delay: 30

    - name: Create starter gitea user
      tags:
        - gitea
      ansible.builtin.uri:
        url: https://gitea-gitea.apps.{{ extracted_domain }}/api/v1/admin/users
        method: POST
        body: "{{ body }}"
        status_code: 201
        body_format: json
        validate_certs: false
        user: "gitadmin"
        password: "redhat123"
        force_basic_auth: true
      vars:
        body: >-
          {
            "email": "foo@example.com",
            "login_name": "starter",
            "must_change_password": false,
            "password": "redhat123",
            "send_notify": false,
            "username": "starter"
          }
      ignore_errors: true

    - name: Fetch starter user ID from gitea
      tags:
        - gitea
      shell: |
        PODNAME=$(oc get pods -n gitea --selector app=gitea -o custom-columns=POD:.metadata.name --no-headers)
        oc exec $PODNAME -n gitea -- ./gitea --config conf/app.ini admin user list | grep starter | awk '{ print $1 }'
      register: starter_output

    - name: Set starter_id fact
      tags:
        - gitea
      set_fact:
        starter_id: "{{ starter_output.stdout }}"

    - name: Fork starter repos
      tags:
        - gitea
      ansible.builtin.uri:
        url: https://gitea-gitea.apps.{{ extracted_domain }}/api/v1/repos/migrate
        method: POST
        body: "{{ body }}"
        status_code: 201
        body_format: json
        validate_certs: false
        user: "starter"
        password: "redhat123"
        force_basic_auth: true
      vars:
        body: >-
          {
            "clone_addr": "{{ item.url }}",
            "description": "",
            "issues": false,
            "milestones": false,
            "mirror": false,
            "private": false,
            "repo_name": "{{ item.name }}",
            "uid": {{ starter_id }}
          }
      with_items:
        - { url: 'https://github.com/catalyst-ctfd/python-starter.git', name: 'python-starter' }
        - { url: 'https://github.com/catalyst-ctfd/node-starter.git', name: 'node-starter' }
        - { url: 'https://github.com/catalyst-ctfd/springboot-starter.git', name: 'springboot-starter' }
        - { url: 'https://github.com/catalyst-ctfd/quarkus-starter.git', name: 'quarkus-starter' }
      ignore_errors: true

    - name: create morse configmaps
      kubernetes.core.k8s:
        namespace: "player{{ item }}"
        definition:
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: morse-code
          data:
            morse-code.csv: |
              !,-.-.--
              $,...-..-
              &,.-...
              ',.----.
              (,-.--.
              ),-.--.-
              +,.-.-.
              -,-....-
              .,.-.-.-
              /,-..-.
              0,-----
              1,.----
              2,..---
              3,...--
              4,....-
              5,.....
              6,-....
              7,--...
              8,---..
              9,----.
              :,---...
              ;,-.-.-.
              =,-...-
              ?,..--..
              @,.--.-.
              A,.-
              B,-...
              C,-.-.
              D,-..
              E,.
              F,..-.
              G,--.
              H,....
              I,..
              J,.---
              K,-.-
              L,.-..
              M,--
              N,-.
              O,---
              P,.--.
              Q,--.-
              R,.-.
              S,...
              T,-
              U,..-
              V,...-
              W,.--
              X,-..-
              Y,-.--
              Z,--..
              _,..--.-
          state: present
          wait: yes
      with_sequence: start=1 end={{ player_count }}
      retries: 20
      delay: 15

    - name: create treasure configmaps
      kubernetes.core.k8s:
        namespace: "player{{ item }}"
        definition:
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: treasure
          data:
            map: eC1tYXJrcy10aGUtc3BvdAo=
          state: present
          wait: yes
      with_sequence: start=1 end={{ player_count }}
      retries: 20
      delay: 15

    - name: Create INSTRUCTIONS repo in Gitea
      ansible.builtin.uri:
        url: https://gitea-gitea.apps.{{ extracted_domain }}/api/v1/user/repos
        method: POST
        body_format: json
        validate_certs: false
        user: "starter"
        password: "redhat123"
        force_basic_auth: true
        body:
          name: "INSTRUCTIONS"
          description: "Instructions Repository"
          private: false
      register: repo_response
      ignore_errors: true

    - name: Generate README.md from template
      template:
        src: STARTER-README.j2
        dest: /tmp/README.md
      vars:
        cluster_domain: "{{ extracted_domain }}"

    - name: Ensure INSTRUCTIONS directory is absent
      ansible.builtin.file:
        path: /tmp/INSTRUCTIONS
        state: absent

    - name: Ensure INSTRUCTIONS directory is present
      ansible.builtin.file:
        path: /tmp/INSTRUCTIONS
        state: directory

    - name: Move README.md to INSTRUCTIONS directory
      ansible.builtin.copy:
        src: '/tmp/README.md'
        dest: '/tmp/INSTRUCTIONS/README.md'
        remote_src: yes

    - name: Move images to INSTRUCTIONS repo
      ansible.builtin.copy:
        src: 'images'
        dest: '/tmp/INSTRUCTIONS/images/'
        remote_src: yes

    - name: Add, commit, and push README.md
      shell: |
        git init
        git add README.md images
        git commit -m "New files"
        git remote add origin "https://starter:redhat123@gitea-gitea.apps.{{ extracted_domain }}/starter/INSTRUCTIONS.git"
        git push --set-upstream origin master
      args:
        chdir: "/tmp/INSTRUCTIONS"
      environment:
        GIT_COMMITTER_NAME: "starter"
        GIT_COMMITTER_EMAIL: "starter@example.com"
        GIT_AUTHOR_NAME: "starter"
        GIT_AUTHOR_EMAIL: "starter@example.com"
      ignore_errors: true

    - name: delete old island-logs configmaps
      shell: |
        oc delete cm island-logs -n player{{ item }} --ignore-not-found=true
      with_sequence: start=1 end={{ player_count }}
      ignore_errors: true

    - name: create island-logs configmaps
      shell: |
        oc create cm island-logs --from-file="{{ playbook_dir }}/island-logs.sql" -n "player{{ item }}"
      with_sequence: start=1 end={{ player_count }}
      retries: 20
      delay: 15

    - name: create treasure key pvc
      tags:
        - pv-challenge
      kubernetes.core.k8s:
        namespace: "player{{ item }}"
        definition:
          apiVersion: v1
          kind: PersistentVolumeClaim
          metadata:
            name: treasure-key-pvc
            labels:
              app: treasure-key-pvc
          spec:
            accessModes:
            - ReadWriteOnce
            resources:
              requests:
                storage: 1Mi
      with_sequence: start=1 end={{ player_count }}
      retries: 20
      delay: 15

    - name: Deploy treasure-key pod to mount the mykey file to pv
      tags:
        - pv-challenge
      kubernetes.core.k8s:
        namespace: "player{{ item }}"
        definition:
          apiVersion: v1
          kind: Pod
          metadata:
            name: treasure-key-pod
          spec:
            volumes:
              - name: treasure-key-vol
                persistentVolumeClaim:
                  claimName: treasure-key-pvc
            containers:
              - name: treasure-key-container
                image: registry.access.redhat.com/ubi8/httpd-24:1-274.1692780861
                ports:
                  - containerPort: 8080
                    name: "http-server"
                volumeMounts:
                  - mountPath: "/tmp/treasure-key/"
                    name: treasure-key-vol
            initContainers:
              - command:
                  - /bin/bash
                  - '-c'
                  - >-
                      echo "MjcwNTYK" > /tmp/treasure-key/mykey.txt;
                image: registry.redhat.io/openshift4/ose-cli
                imagePullPolicy: IfNotPresent
                name: my-init-container
                volumeMounts:
                  - name: treasure-key-vol
                    mountPath: /tmp/treasure-key/
      with_sequence: start=1 end={{ player_count }}
      retries: 20
      delay: 15

    - name: delete treasure-key pod after mounting the treasure key file
      tags:
        - pv-challenge
      shell: |
        oc delete pod treasure-key-pod -n player{{ item }}
      with_sequence: start=1 end={{ player_count }}
      retries: 20
      delay: 15

    - name: Disable project creation for players
      shell: |
        oc patch clusterrolebinding.rbac self-provisioners -p '{"subjects": null}'
      retries: 20
      delay: 15

    - name: install web cli operator
      tags:
        - web-terminal
      shell: |
        oc apply -f web-cli-operator/subscription.yaml -n openshift-operators
